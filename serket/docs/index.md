---
layout: default
---

Serket is a library for constructing large-scale models and estimating their parameters via the connection of the modules.
You can use the following probabilistic models and neural network models:

- Multimodal latent Dirichlet allocation
- Gaussian mixture model
- AutoEncoder
- Hidden Markov model
- Speech recognition with language model learning

Serket makes it possible to construct large-scale models by connecting these modules.


## Contributors

- Ryo Kuniyasu
- Tomoaki Nakamura
- Takayuki Nagai
- Tadahiro Taniguchi

## Citation
The concept of Serket is described in the following paper:

```
@article{nakamura2017serket,
title={SERKET: An Architecture For Connecting Stochastic Models to Realize a Large-Scale Cognitive Model},
author={Nakamura, Tomoaki and Nagai, Takayuki and Taniguchi, Tadahiro},
journal={Frontiers in Neurorobotics},
volume={12},
year={2017}}
```

We have also published a Japanese paper describing some of the modules:

```
國安瞭，中村友昭，青木達哉，谷口彰，尾崎僚，伊志嶺朝良，横山裕樹，小椋忠志，長井隆行，谷口忠大，”確率モデルの統合による大規模なモデルの実現 ～VAE, GMM, HMM, MLDAの統合モデルの実装と評価～”，情報論的学習理論ワークショップ，T-34，Nov. 2018
```
```
國安瞭，中村友昭，長井隆行，谷口忠大，”確率モデルの統合によるマルチモーダル学習モデルの構築”，人工知能学会全国大会，1L4-J-11-02，Jun. 2019
```
